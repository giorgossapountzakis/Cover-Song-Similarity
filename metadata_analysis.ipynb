{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TACOSMetadataAnalyzer:\n",
    "    def __init__(self, metadata_path):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer for the TACOS dataset metadata.\n",
    "        \n",
    "        The metadata is organized hierarchically:\n",
    "        - Top level: Work IDs (W_xxxxx) representing original songs\n",
    "        - Second level: Performance IDs (P_xxxxx) representing different versions\n",
    "        \"\"\"\n",
    "        self.metadata_path = Path(metadata_path)\n",
    "        self.works_data = None\n",
    "        # Dictionary to store organized cover relationships\n",
    "        self.cover_relationships = {}\n",
    "        \n",
    "    def load_metadata(self):\n",
    "        \"\"\"\n",
    "        Load the metadata JSON file and organize it into cover relationships.\n",
    "        The file structure has works (original songs) containing multiple performances (versions).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(self.metadata_path, 'r', encoding='utf-8') as f:\n",
    "                self.works_data = json.load(f)\n",
    "            \n",
    "            # Process each work (original song) and its performances (versions)\n",
    "            for work_id, performances in self.works_data.items():\n",
    "                # Get the first performance to extract work (original song) information\n",
    "                first_perf = next(iter(performances.values()))\n",
    "                \n",
    "                # Create entry for this work\n",
    "                self.cover_relationships[work_id] = {\n",
    "                    'work_title': first_perf['work_title'],\n",
    "                    'work_artist': first_perf['work_artist'],\n",
    "                    'performances': []\n",
    "                }\n",
    "                \n",
    "                # Add all performances (including different versions)\n",
    "                for perf_id, perf_data in performances.items():\n",
    "                    performance = {\n",
    "                        'title': perf_data['perf_title'],\n",
    "                        'artist': perf_data['perf_artist'],\n",
    "                        'year': perf_data.get('release_year', 'Unknown'),\n",
    "                        'performance_id': perf_id,\n",
    "                        'instrumental': perf_data.get('instrumental', 'Unknown')\n",
    "                    }\n",
    "                    self.cover_relationships[work_id]['performances'].append(performance)\n",
    "                \n",
    "                # Add count of covers\n",
    "                self.cover_relationships[work_id]['number_of_covers'] = len(performances) \n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading metadata: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def print_cover_relationships(self, min_covers=0):\n",
    "        \"\"\"\n",
    "        Print organized information about each work and its covers.\n",
    "        \n",
    "        Args:\n",
    "            min_covers (int): Minimum number of covers to include in output\n",
    "        \"\"\"\n",
    "        if not self.cover_relationships:\n",
    "            print(\"No data loaded. Please run load_metadata() first.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nFound {len(self.cover_relationships)} works with performances:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for work_id, work_info in self.cover_relationships.items():\n",
    "            if work_info['number_of_covers'] >= min_covers:\n",
    "                print(f\"\\nOriginal Work: '{work_info['work_title']}'\")\n",
    "                print(f\"Original Artist: {work_info['work_artist']}\")\n",
    "                print(f\"Number of covers: {work_info['number_of_covers']}\")\n",
    "                \n",
    "                print(\"\\nPerformances:\")\n",
    "                for idx, perf in enumerate(work_info['performances'], 1):\n",
    "                    print(f\"{idx}. '{perf['title']}' by {perf['artist']} ({perf['year']})\")\n",
    "                    print(f\"   Instrumental: {perf['instrumental']}\")\n",
    "                print(\"-\" * 80)\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"\n",
    "        Calculate and return statistics about the dataset.\n",
    "        \"\"\"\n",
    "        if not self.cover_relationships:\n",
    "            return None\n",
    "        \n",
    "        stats = {\n",
    "            'total_works': len(self.cover_relationships),\n",
    "            'total_performances': sum(len(work['performances']) \n",
    "                                   for work in self.cover_relationships.values()),\n",
    "            'works_with_covers': sum(1 for work in self.cover_relationships.values() \n",
    "                                   if work['number_of_covers'] > 0),\n",
    "            'most_covered': sorted(\n",
    "                [(work['work_title'], work['number_of_covers']) \n",
    "                 for work in self.cover_relationships.values()],\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True\n",
    "            )[:5],\n",
    "            'instrumental_count': sum(\n",
    "                sum(1 for perf in work['performances'] if perf['instrumental'] == 'Yes')\n",
    "                for work in self.cover_relationships.values()\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Calculate average covers per work\n",
    "        stats['avg_covers_per_work'] = (stats['total_performances'] - stats['total_works']) / stats['total_works']\n",
    "        \n",
    "        return stats\n",
    "\n",
    "    def find_work_by_artist(self, artist_name):\n",
    "        \"\"\"\n",
    "        Find all works performed by a specific artist.\n",
    "        \n",
    "        Args:\n",
    "            artist_name (str): Name of the artist to search for\n",
    "        \"\"\"\n",
    "        found_works = []\n",
    "        for work_id, work_info in self.cover_relationships.items():\n",
    "            # Check original artist\n",
    "            if artist_name.lower() in work_info['work_artist'].lower():\n",
    "                found_works.append({\n",
    "                    'work_title': work_info['work_title'],\n",
    "                    'role': 'original artist',\n",
    "                    'number_of_covers': work_info['number_of_covers']\n",
    "                })\n",
    "            \n",
    "            # Check cover artists\n",
    "            for perf in work_info['performances']:\n",
    "                if artist_name.lower() in perf['artist'].lower():\n",
    "                    if perf['artist'].lower() != work_info['work_artist'].lower():\n",
    "                        found_works.append({\n",
    "                            'work_title': work_info['work_title'],\n",
    "                            'role': 'cover artist',\n",
    "                            'year': perf['year'],\n",
    "                            'original_artist': work_info['work_artist']\n",
    "                        })\n",
    "        \n",
    "        return found_works\n",
    "\n",
    "    def plot_covers_distribution(self):\n",
    "        \"\"\"\n",
    "        Creates a histogram showing the distribution of how many songs have a certain number of covers.\n",
    "        This visualization helps understand if most songs have few covers or if there are many songs\n",
    "        with numerous covers.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Extract the number of covers for each work\n",
    "        covers_per_work = [work['number_of_covers'] \n",
    "                        for work in self.cover_relationships.values()]\n",
    "        \n",
    "        # Set up the plot style for better readability\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        \n",
    "        # Create the histogram\n",
    "        # We use bins='auto' to let matplotlib determine optimal bin size\n",
    "        plt.hist(covers_per_work, bins='auto', edgecolor='black', alpha=0.7)\n",
    "        \n",
    "        # Enhance the plot with labels and title\n",
    "        plt.xlabel('Number of Covers', fontsize=12)\n",
    "        plt.ylabel('Number of Original Works', fontsize=12)\n",
    "        plt.title('Distribution of Covers per Original Work', fontsize=14, pad=20)\n",
    "        \n",
    "        # Add statistical annotations\n",
    "        avg_covers = sum(covers_per_work) / len(covers_per_work)\n",
    "        max_covers = max(covers_per_work)\n",
    "        \n",
    "        # Add text box with statistics\n",
    "        stats_text = (f'Total Works: {len(covers_per_work)}\\n'\n",
    "                    f'Average Covers: {avg_covers:.1f}\\n'\n",
    "                    f'Maximum Covers: {max_covers}')\n",
    "        \n",
    "        plt.text(0.95, 0.95, stats_text,\n",
    "                transform=plt.gca().transAxes,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout to prevent text cutoff\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        # Print additional insights about the distribution\n",
    "        print(\"\\nDistribution Insights:\")\n",
    "        print(f\"Most common: {max(set(covers_per_work), key=covers_per_work.count)} covers\")\n",
    "        print(f\"Number of works with no covers: \"\n",
    "            f\"{sum(1 for x in covers_per_work if x == 0)}\")\n",
    "        print(f\"Number of works with 5+ covers: \"\n",
    "            f\"{sum(1 for x in covers_per_work if x >= 5)}\")\n",
    "\n",
    "    def create_cover_key_mapping(self):\n",
    "        \"\"\"\n",
    "        Creates a focused mapping of only songs that have covers, storing just the key relationships.\n",
    "        \n",
    "        This method analyzes the loaded metadata and creates a streamlined mapping structure that:\n",
    "        1. Only includes works that have at least one cover version\n",
    "        2. Stores just the work_id (original) and performance_ids (covers) relationships\n",
    "        3. Maintains a clean, memory-efficient structure for quick lookups\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary where:\n",
    "                - key: work_id of the original song\n",
    "                - value: list of performance_ids of its covers\n",
    "                \n",
    "        Example output format:\n",
    "        {\n",
    "            'W_00001': ['P_00002', 'P_00003'],  # Original work -> Cover performance IDs\n",
    "            'W_00004': ['P_00008', 'P_00009', 'P_00010']\n",
    "        }\n",
    "        \"\"\"\n",
    "        if not self.works_data:\n",
    "            print(\"No data loaded. Please run load_metadata() first.\")\n",
    "            return None\n",
    "        \n",
    "        # Initialize our cover relationships dictionary\n",
    "        cover_key_mapping = {}\n",
    "        \n",
    "        for work_id, performances in self.works_data.items():\n",
    "            # Get the first performance (original version)\n",
    "            first_perf_id = min(performances.keys())\n",
    "            \n",
    "            # Get all cover performance IDs (excluding the original)\n",
    "            cover_perf_ids = [pid for pid in performances.keys() if pid != first_perf_id]\n",
    "            \n",
    "            # Only include works that have at least one cover\n",
    "            if cover_perf_ids:\n",
    "                cover_key_mapping[work_id] = cover_perf_ids\n",
    "        \n",
    "        # Store statistics as class attribute for later use\n",
    "        self.key_mapping_stats = {\n",
    "            'total_works_with_covers': len(cover_key_mapping),\n",
    "            'total_cover_performances': sum(len(covers) for covers in cover_key_mapping.values()),\n",
    "            'max_covers': max(len(covers) for covers in cover_key_mapping.values()) if cover_key_mapping else 0,\n",
    "            'min_covers': min(len(covers) for covers in cover_key_mapping.values()) if cover_key_mapping else 0\n",
    "        }\n",
    "        \n",
    "        return cover_key_mapping                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = TACOSMetadataAnalyzer(r'D:\\TACOS\\da-tacos_metadata\\da-tacos_metadata\\da-tacos_benchmark_subset_metadata.json')\n",
    "analyzer.load_metadata()\n",
    "analyzer.print_cover_relationships(min_covers=1)  # Show only songs with at least 2 covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "stats = analyzer.get_statistics()\n",
    "pprint(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_works = analyzer.find_work_by_artist(\"Flea\")\n",
    "pprint(artist_works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.plot_covers_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_mapping=analyzer.create_cover_key_mapping()\n",
    "with open(\"cover_mapping.json\", \"w\") as outfile: \n",
    "    json.dump(cover_mapping, outfile,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
